{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhihsan/abd/blob/main/project_kelompok/NER_kelompok_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA21Jo5d9SVq"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NER_LAB.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdjHkAW8TB"
      },
      "source": [
        "# **Detect lab results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uDmeHEFW7_h"
      },
      "source": [
        "To run this yourself, you will need to upload your license keys to the notebook. Just Run The Cell Below in order to do that. Also You can open the file explorer on the left side of the screen and upload `license_keys.json` to the folder that opens.\n",
        "Otherwise, you can look at the example outputs at the bottom of the notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIeCOiJNW-88"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMIDv74CYN0d"
      },
      "source": [
        "Import license keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "ttHPIV2JXbIM",
        "outputId": "4d804253-2f22-4c7e-d40a-2f3a6bc6accc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7260658e-1596-40d6-b881-1fb6b4eb5304\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7260658e-1596-40d6-b881-1fb6b4eb5304\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving spark_nlp_for_healthcare_spark_ocr_4546.json to spark_nlp_for_healthcare_spark_ocr_4546.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQtc1CHaYQjU"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGJktFHdHL1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87bfca84-ab24-40ad-ad63-bc4c157c555f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 70 kB/s \n",
            "\u001b[K     |████████████████████████████████| 142 kB 20.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 66.0 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 148 kB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 95 kB 2.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 66 kB 3.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
        "\n",
        "# Installing Spark NLP Display Library for visualization\n",
        "! pip install -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj5FRDV4YSXN"
      },
      "source": [
        "Import dependencies into Python and start the Spark session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw-t1zxlHTB7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp_jsl\n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET']) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Initialization"
      ],
      "metadata": {
        "id": "Vrexwu-iDE6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload dataset mtsamples\n",
        "f = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "Z3oqA5CmDF1b",
        "outputId": "dab98f2f-7e41-45e0-c5bc-b6a18ade6332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d93bc1c3-2f54-4aac-81c2-c4c50a692d6b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d93bc1c3-2f54-4aac-81c2-c4c50a692d6b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read csv to pandas\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/mtsamples_20220222.csv')\n",
        "df = df.dropna()\n",
        "df = df.drop_duplicates()\n",
        "df.head(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Nhf7bGv_DNyI",
        "outputId": "1bc0d8b5-1381-46b9-c8aa-b2992dbf7a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     medical_speciality                 sample_name  \\\n",
              "0  Allergy / Immunology           Allergic Rhinitis   \n",
              "1  Allergy / Immunology  Allergy Evaluation Consult   \n",
              "2  Allergy / Immunology      Asthma in a 5-year-old   \n",
              "3  Allergy / Immunology           Chronic Sinusitis   \n",
              "\n",
              "                                         description  \\\n",
              "0  A 23-year-old white female presents with compl...   \n",
              "1  Acute allergic reaction, etiology uncertain, h...   \n",
              "2   Mother states he has been wheezing and coughing.   \n",
              "3  Patient having severe sinusitis about two to t...   \n",
              "\n",
              "                                       transcription  \\\n",
              "0  SUBJECTIVE: This 23-year-old white female pres...   \n",
              "1  HISTORY: A 34-year-old male presents today sel...   \n",
              "2  CHIEF COMPLAINT: This 5-year-old male presents...   \n",
              "3  HISTORY: I had the pleasure of meeting and eva...   \n",
              "\n",
              "                                            keywords  \n",
              "0  allergy / immunology, allergic rhinitis, aller...  \n",
              "1  allergy / immunology, keflex, acute allergic r...  \n",
              "2  allergy / immunology, breathing treatment, air...  \n",
              "3  allergy / immunology, nasal congestion, facial...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed0b6398-6c25-4f6b-80cd-2e15fabcb2e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>medical_speciality</th>\n",
              "      <th>sample_name</th>\n",
              "      <th>description</th>\n",
              "      <th>transcription</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Allergy / Immunology</td>\n",
              "      <td>Allergic Rhinitis</td>\n",
              "      <td>A 23-year-old white female presents with compl...</td>\n",
              "      <td>SUBJECTIVE: This 23-year-old white female pres...</td>\n",
              "      <td>allergy / immunology, allergic rhinitis, aller...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Allergy / Immunology</td>\n",
              "      <td>Allergy Evaluation Consult</td>\n",
              "      <td>Acute allergic reaction, etiology uncertain, h...</td>\n",
              "      <td>HISTORY: A 34-year-old male presents today sel...</td>\n",
              "      <td>allergy / immunology, keflex, acute allergic r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Allergy / Immunology</td>\n",
              "      <td>Asthma in a 5-year-old</td>\n",
              "      <td>Mother states he has been wheezing and coughing.</td>\n",
              "      <td>CHIEF COMPLAINT: This 5-year-old male presents...</td>\n",
              "      <td>allergy / immunology, breathing treatment, air...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Allergy / Immunology</td>\n",
              "      <td>Chronic Sinusitis</td>\n",
              "      <td>Patient having severe sinusitis about two to t...</td>\n",
              "      <td>HISTORY: I had the pleasure of meeting and eva...</td>\n",
              "      <td>allergy / immunology, nasal congestion, facial...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed0b6398-6c25-4f6b-80cd-2e15fabcb2e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed0b6398-6c25-4f6b-80cd-2e15fabcb2e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed0b6398-6c25-4f6b-80cd-2e15fabcb2e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concat sample_name, description, and transcription columns, then lower\n",
        "# df['text'] = df.apply(lambda x: x['sample_name'] +' '+ x['description'] +' '+ x['transcription'], axis=1).str.lower()\n",
        "\n",
        "# only use transcription columns for input  \n",
        "df['text'] = df.apply(lambda x: x['transcription'], axis=1).str.lower()\n",
        "\n",
        "# a little bit preprocesing delete unknown characters\n",
        "text_to_filter = ' '.join(df.text.values.flatten().tolist())\n",
        "import re, numpy as np\n",
        "excluded = [ st for st in np.unique(re.findall(r'.', text_to_filter)) if not re.search(r'[a-z]', st) and not re.search(r'[0-9]', st) and st not in ['%','/','-','!',' ']]\n",
        "print(excluded)\n",
        "for exc in excluded:\n",
        "    df['text'] = df['text'].str.replace(exc, '')\n",
        "df['text'] = df['text'].str.replace('\\n', ' ')\n",
        "df['text'] = df['text'].astype(str)\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "h4_YfyePIDxw",
        "outputId": "df0bc539-7e30-4f26-f954-7f902e23325f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"', '#', '$', '&', \"'\", '(', ')', '*', '+', ',', '.', ':', ';', '<', '=', '>', '?', '@', '[', ']', '_', '{', '|', '}', '©', '®', '°', 'µ', '·', 'º', '¼', '½', 'è', 'é', 'ü', '–', '’', '“', '”', '…']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     medical_speciality                 sample_name  \\\n",
              "0  Allergy / Immunology           Allergic Rhinitis   \n",
              "1  Allergy / Immunology  Allergy Evaluation Consult   \n",
              "2  Allergy / Immunology      Asthma in a 5-year-old   \n",
              "3  Allergy / Immunology           Chronic Sinusitis   \n",
              "4  Allergy / Immunology     Evaluation of Allergies   \n",
              "\n",
              "                                         description  \\\n",
              "0  A 23-year-old white female presents with compl...   \n",
              "1  Acute allergic reaction, etiology uncertain, h...   \n",
              "2   Mother states he has been wheezing and coughing.   \n",
              "3  Patient having severe sinusitis about two to t...   \n",
              "4  Chronic glossitis, xerostomia, probable enviro...   \n",
              "\n",
              "                                       transcription  \\\n",
              "0  SUBJECTIVE: This 23-year-old white female pres...   \n",
              "1  HISTORY: A 34-year-old male presents today sel...   \n",
              "2  CHIEF COMPLAINT: This 5-year-old male presents...   \n",
              "3  HISTORY: I had the pleasure of meeting and eva...   \n",
              "4  HISTORY: A 55-year-old female presents self-re...   \n",
              "\n",
              "                                            keywords  \\\n",
              "0  allergy / immunology, allergic rhinitis, aller...   \n",
              "1  allergy / immunology, keflex, acute allergic r...   \n",
              "2  allergy / immunology, breathing treatment, air...   \n",
              "3  allergy / immunology, nasal congestion, facial...   \n",
              "4  allergy / immunology, chronic glossitis, xeros...   \n",
              "\n",
              "                                                text  \n",
              "0  subjective this 23-year-old white female prese...  \n",
              "1  history a 34-year-old male presents today self...  \n",
              "2  chief complaint this 5-year-old male presents ...  \n",
              "3  history i had the pleasure of meeting and eval...  \n",
              "4  history a 55-year-old female presents self-ref...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75fbdaa4-39ec-4e9e-9758-7b3234e82835\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>medical_speciality</th>\n",
              "      <th>sample_name</th>\n",
              "      <th>description</th>\n",
              "      <th>transcription</th>\n",
              "      <th>keywords</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Allergy / Immunology</td>\n",
              "      <td>Allergic Rhinitis</td>\n",
              "      <td>A 23-year-old white female presents with compl...</td>\n",
              "      <td>SUBJECTIVE: This 23-year-old white female pres...</td>\n",
              "      <td>allergy / immunology, allergic rhinitis, aller...</td>\n",
              "      <td>subjective this 23-year-old white female prese...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Allergy / Immunology</td>\n",
              "      <td>Allergy Evaluation Consult</td>\n",
              "      <td>Acute allergic reaction, etiology uncertain, h...</td>\n",
              "      <td>HISTORY: A 34-year-old male presents today sel...</td>\n",
              "      <td>allergy / immunology, keflex, acute allergic r...</td>\n",
              "      <td>history a 34-year-old male presents today self...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Allergy / Immunology</td>\n",
              "      <td>Asthma in a 5-year-old</td>\n",
              "      <td>Mother states he has been wheezing and coughing.</td>\n",
              "      <td>CHIEF COMPLAINT: This 5-year-old male presents...</td>\n",
              "      <td>allergy / immunology, breathing treatment, air...</td>\n",
              "      <td>chief complaint this 5-year-old male presents ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Allergy / Immunology</td>\n",
              "      <td>Chronic Sinusitis</td>\n",
              "      <td>Patient having severe sinusitis about two to t...</td>\n",
              "      <td>HISTORY: I had the pleasure of meeting and eva...</td>\n",
              "      <td>allergy / immunology, nasal congestion, facial...</td>\n",
              "      <td>history i had the pleasure of meeting and eval...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Allergy / Immunology</td>\n",
              "      <td>Evaluation of Allergies</td>\n",
              "      <td>Chronic glossitis, xerostomia, probable enviro...</td>\n",
              "      <td>HISTORY: A 55-year-old female presents self-re...</td>\n",
              "      <td>allergy / immunology, chronic glossitis, xeros...</td>\n",
              "      <td>history a 55-year-old female presents self-ref...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75fbdaa4-39ec-4e9e-9758-7b3234e82835')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75fbdaa4-39ec-4e9e-9758-7b3234e82835 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75fbdaa4-39ec-4e9e-9758-7b3234e82835');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get 10 random samples for each top 25 medical_speciality  \n",
        "df = pd.concat([df[df.medical_speciality==_].sample(10, random_state=10) for _ in df.medical_speciality.value_counts()[:25].index], axis=0).reset_index(drop=False)"
      ],
      "metadata": {
        "id": "ifnm7l6r9agl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save to csv on column text \n",
        "df[['text']].to_csv('data.csv', index=False)\n",
        "pd.read_csv('data.csv').shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u87XVwH1JJ2U",
        "outputId": "a4fc7d5a-0b22-45fa-fae2-8a8b5157612d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.medical_speciality.value_counts()[:25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRsLTSpr2OZD",
        "outputId": "02234825-610d-4445-d1c9-34f644d48e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Surgery                          10\n",
              "Neurosurgery                     10\n",
              "Dermatology                      10\n",
              "Podiatry                         10\n",
              "Office Notes                     10\n",
              "Psychiatry / Psychology          10\n",
              "Pain Management                  10\n",
              "Pediatrics - Neonatal            10\n",
              "Emergency Room Reports           10\n",
              "Nephrology                       10\n",
              "Ophthalmology                    10\n",
              "Hematology - Oncology            10\n",
              "ENT - Otolaryngology             10\n",
              "Consult - History and Phy.       10\n",
              "Discharge Summary                10\n",
              "Urology                          10\n",
              "Obstetrics / Gynecology          10\n",
              "SOAP / Chart / Progress Notes    10\n",
              "Neurology                        10\n",
              "Gastroenterology                 10\n",
              "General Medicine                 10\n",
              "Radiology                        10\n",
              "Orthopedic                       10\n",
              "Cardiovascular / Pulmonary       10\n",
              "Dentistry                        10\n",
              "Name: medical_speciality, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data to spark"
      ],
      "metadata": {
        "id": "mgTUYzDqJ5fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark.read.csv('data.csv', header=True, inferSchema=True)\n",
        "data.show(truncate=90)\n",
        "data.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0OT_fpRJ8O0",
        "outputId": "cd68df3b-4c11-40ec-a579-52a3b78f81bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------+\n",
            "|                                                                                      text|\n",
            "+------------------------------------------------------------------------------------------+\n",
            "|procedure total hip replacement  procedure description the patient was bought to the op...|\n",
            "|procedure performed cataract extraction with lens implantation right eye  description o...|\n",
            "|preop diagnoses 1 left pilon fracture 2 left great toe proximal phalanx fracture  posto...|\n",
            "|preoperative diagnosis recurrent bladder tumors  postoperative diagnosis recurrent blad...|\n",
            "|preoperative diagnosis degenerative disk disease at l4-l5 and l5-s1  postoperative diag...|\n",
            "|the patient was consented for skin biopsy the complications instructions as to how the ...|\n",
            "|preoperative diagnosis varicose veins  postoperative diagnosis varicose veins  procedur...|\n",
            "|preoperative diagnosis t12 compression fracture with cauda equina syndrome and spinal c...|\n",
            "|preoperative diagnoses 1 dysphagia 2 right parapharyngeal hemorrhagic lesion  postopera...|\n",
            "|admitting diagnosis right c5-c6 herniated nucleus pulposus  primary operative procedure...|\n",
            "|reason for consultation mesothelioma  history of present illness the patient is a 73-ye...|\n",
            "|reason for referral the patient was referred to me by dr x of the hospitalist service a...|\n",
            "|history of present illness this is the initial clinic visit for a 41-year-old worker wh...|\n",
            "|cc slowing of motor skills and cognitive function  hx this 42 y/o lhm presented on 3/16...|\n",
            "|history of present illness the patient is an 85-year-old gentleman who follows as an ou...|\n",
            "|history neurologic consultation was requested to assess and assist with her seizure med...|\n",
            "|type of consultation wound care consult  history of present illness the patient is a 62...|\n",
            "|the patient is a 51-year-old female who was undergoing a routine physical examination a...|\n",
            "|chief complaint palpitations  chest pain / unspecified angina pectoris history the pati...|\n",
            "|reason for referral the patient is a 76-year-old caucasian gentleman who works full-tim...|\n",
            "+------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_col = 'text'\n",
        "review_text = data.select(text_col).filter(F.col(text_col).isNotNull())"
      ],
      "metadata": {
        "id": "iK9LqdQGQD7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Define spark pipeline - standard preprocessing (BiGram, NGram, and POSTagging)"
      ],
      "metadata": {
        "id": "DADT55XOJ8jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.base import DocumentAssembler\n",
        "from sparknlp.annotator import Tokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from sparknlp.annotator import StopWordsCleaner\n",
        "from sparknlp.annotator import NGramGenerator\n",
        "from sparknlp.annotator import PerceptronModel\n",
        "from sparknlp.base import Finisher\n",
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.annotator import Normalizer\n",
        "from sparknlp.annotator import LemmatizerModel\n",
        "import nltk\n",
        "\n",
        "documentAssembler = DocumentAssembler() \\\n",
        "     .setInputCol(text_col) \\\n",
        "     .setOutputCol('document')\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "     .setInputCols(['document']) \\\n",
        "     .setOutputCol('tokenized')\n",
        "\n",
        "normalizer = Normalizer() \\\n",
        "     .setInputCols(['tokenized']) \\\n",
        "     .setOutputCol('normalized') \\\n",
        "     .setLowercase(True)\n",
        "\n",
        "lemmatizer = LemmatizerModel.pretrained() \\\n",
        "     .setInputCols(['normalized']) \\\n",
        "     .setOutputCol('lemmatized')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "eng_stopwords = stopwords.words('english')\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner() \\\n",
        "     .setInputCols(['lemmatized']) \\\n",
        "     .setOutputCol('unigrams') \\\n",
        "     .setStopWords(eng_stopwords)\n",
        "\n",
        "ngrammer = NGramGenerator() \\\n",
        "    .setInputCols(['lemmatized']) \\\n",
        "    .setOutputCol('ngrams') \\\n",
        "    .setN(3) \\\n",
        "    .setEnableCumulative(True) \\\n",
        "    .setDelimiter('_')\n",
        "\n",
        "pos_tagger = PerceptronModel.pretrained('pos_anc') \\\n",
        "    .setInputCols(['document', 'lemmatized']) \\\n",
        "    .setOutputCol('pos')\n",
        "\n",
        "finisher = Finisher() \\\n",
        "     .setInputCols(['unigrams', 'ngrams', 'pos']) \\\n",
        "\n",
        "pipeline = Pipeline() \\\n",
        "     .setStages([documentAssembler,                  \n",
        "                 tokenizer,\n",
        "                 normalizer,                  \n",
        "                 lemmatizer,                  \n",
        "                 stopwords_cleaner, \n",
        "                 ngrammer,  \n",
        "                 pos_tagger,\n",
        "                 finisher])                  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOOz7htuFYSc",
        "outputId": "121b508d-4666-4e50-e4d9-e2844e1d4fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "pos_anc download started this may take some time.\n",
            "Approximate size to download 3.9 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_review = pipeline.fit(review_text).transform(review_text)\n",
        "processed_review.limit(5).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmJs85ONQlL8",
        "outputId": "27998a46-25f4-4c37-ede2-4c44f822659d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|   finished_unigrams|     finished_ngrams|        finished_pos|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|procedure total h...|[procedure, total...|[procedure, total...|[NN, JJ, NN, NN, ...|\n",
            "|procedure perform...|[procedure, perfo...|[procedure, perfo...|[NN, NN, NN, NN, ...|\n",
            "|preop diagnoses 1...|[preop, diagnosis...|[preop, diagnosis...|[NN, NN, NN, NN, ...|\n",
            "|preoperative diag...|[preoperative, di...|[preoperative, di...|[JJ, NN, NN, NN, ...|\n",
            "|preoperative diag...|[preoperative, di...|[preoperative, di...|[JJ, NN, JJ, NN, ...|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import types as T\n",
        "\n",
        "udf_join_arr = F.udf(lambda x: ' '.join(x), T.StringType())\n",
        "processed_review  = processed_review.withColumn('finished_pos', udf_join_arr(F.col('finished_pos')))\n",
        "processed_review.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC1PnciBYaoE",
        "outputId": "f03da9b2-a74b-423b-d65c-137e384a8bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|   finished_unigrams|     finished_ngrams|        finished_pos|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|procedure total h...|[procedure, total...|[procedure, total...|NN JJ NN NN NN NN...|\n",
            "|procedure perform...|[procedure, perfo...|[procedure, perfo...|NN NN NN NN IN NN...|\n",
            "|preop diagnoses 1...|[preop, diagnosis...|[preop, diagnosis...|NN NN NN NN NN NN...|\n",
            "|preoperative diag...|[preoperative, di...|[preoperative, di...|JJ NN NN NN NN JJ...|\n",
            "|preoperative diag...|[preoperative, di...|[preoperative, di...|JJ NN JJ NN NN IN...|\n",
            "|the patient was c...|[patient, consent...|[the, patient, be...|DT NN VB NN IN NN...|\n",
            "|preoperative diag...|[preoperative, di...|[preoperative, di...|JJ NN NN NN JJ NN...|\n",
            "|preoperative diag...|[preoperative, di...|[preoperative, di...|JJ NN NN NN NN IN...|\n",
            "|preoperative diag...|[preoperative, di...|[preoperative, di...|JJ NN NN NN NN JJ...|\n",
            "|admitting diagnos...|[admit, diagnosis...|[admit, diagnosis...|NN NN NN NN NN NN...|\n",
            "|reason for consul...|[reason, consulta...|[reason, for, con...|NN IN NN NN NN IN...|\n",
            "|reason for referr...|[reason, referral...|[reason, for, ref...|NN IN NN DT NN VB...|\n",
            "|history of presen...|[history, present...|[history, of, pre...|NN IN JJ NN DT VB...|\n",
            "|cc slowing of mot...|[cc, slow, motor,...|[cc, slow, of, mo...|NN JJ IN NN NN CC...|\n",
            "|history of presen...|[history, present...|[history, of, pre...|NN IN JJ NN DT NN...|\n",
            "|history neurologi...|[history, neurolo...|[history, neurolo...|NN JJ NN VB NN TO...|\n",
            "|type of consultat...|[type, consultati...|[type, of, consul...|NN IN NN NN NN NN...|\n",
            "|the patient is a ...|[patient, yearold...|[the, patient, be...|DT NN VB DT JJ NN...|\n",
            "|chief complaint p...|[chief, complaint...|[chief, complaint...|JJ NN NN NN NN JJ...|\n",
            "|reason for referr...|[reason, referral...|[reason, for, ref...|NN IN NN DT NN VB...|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_documentAssembler = DocumentAssembler() \\\n",
        "     .setInputCol('finished_pos') \\\n",
        "     .setOutputCol('pos_document')\n",
        "\n",
        "pos_tokenizer = Tokenizer() \\\n",
        "     .setInputCols(['pos_document']) \\\n",
        "     .setOutputCol('pos')\n",
        "\n",
        "pos_ngrammer = NGramGenerator() \\\n",
        "    .setInputCols(['pos']) \\\n",
        "    .setOutputCol('pos_ngrams') \\\n",
        "    .setN(3) \\\n",
        "    .setEnableCumulative(True) \\\n",
        "    .setDelimiter('_')\n",
        "\n",
        "pos_finisher = Finisher() \\\n",
        "     .setInputCols(['pos', 'pos_ngrams']) \\\n",
        "\n",
        "pos_pipeline = Pipeline().setStages([pos_documentAssembler, pos_tokenizer, pos_ngrammer, pos_finisher])"
      ],
      "metadata": {
        "id": "Ly75bryuYb7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_review = pos_pipeline.fit(processed_review).transform(processed_review)\n",
        "processed_review.limit(5).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z58nWobsYc6u",
        "outputId": "7722a8c4-2c6e-4512-d9b8-90af34adb90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|   finished_unigrams|     finished_ngrams|        finished_pos| finished_pos_ngrams|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|procedure total h...|[procedure, total...|[procedure, total...|[NN, JJ, NN, NN, ...|[NN, JJ, NN, NN, ...|\n",
            "|procedure perform...|[procedure, perfo...|[procedure, perfo...|[NN, NN, NN, NN, ...|[NN, NN, NN, NN, ...|\n",
            "|preop diagnoses 1...|[preop, diagnosis...|[preop, diagnosis...|[NN, NN, NN, NN, ...|[NN, NN, NN, NN, ...|\n",
            "|preoperative diag...|[preoperative, di...|[preoperative, di...|[JJ, NN, NN, NN, ...|[JJ, NN, NN, NN, ...|\n",
            "|preoperative diag...|[preoperative, di...|[preoperative, di...|[JJ, NN, JJ, NN, ...|[JJ, NN, JJ, NN, ...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Filtering data"
      ],
      "metadata": {
        "id": "H4NILXEZhrAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_pos(words, pos_tags):\n",
        "    return [word for word, pos in zip(words, pos_tags) \n",
        "            if pos in ['JJ', 'NN', 'NNS', 'VB', 'VBP']]\n",
        "\n",
        "udf_filter_pos = F.udf(filter_pos, T.ArrayType(T.StringType()))\n",
        "processed_review = processed_review.withColumn('filtered_unigrams',\n",
        "                                               udf_filter_pos(F.col('finished_unigrams'), \n",
        "                                                              F.col('finished_pos')))\n",
        "def filter_pos_combs(words, pos_tags):\n",
        "    return [word for word, pos in zip(words, pos_tags) \n",
        "            if (len(pos.split('_')) == 2 and \\\n",
        "                pos.split('_')[0] in ['JJ', 'NN', 'NNS', 'VB', 'VBP'] and \\\n",
        "                 pos.split('_')[1] in ['JJ', 'NN', 'NNS']) \\\n",
        "            or (len(pos.split('_')) == 3 and \\\n",
        "                pos.split('_')[0] in ['JJ', 'NN', 'NNS', 'VB', 'VBP'] and \\\n",
        "                 pos.split('_')[1] in ['JJ', 'NN', 'NNS', 'VB', 'VBP'] and \\\n",
        "                  pos.split('_')[2] in ['NN', 'NNS'])]\n",
        "    \n",
        "udf_filter_pos_combs = F.udf(filter_pos_combs, T.ArrayType(T.StringType()))\n",
        "processed_review = processed_review.withColumn('filtered_ngrams',\n",
        "                                               udf_filter_pos_combs(F.col('finished_ngrams'),\n",
        "                                                                    F.col('finished_pos_ngrams')))\n",
        "from pyspark.sql.functions import concat\n",
        "processed_review = processed_review.withColumn('final', \n",
        "                                               concat(F.col('filtered_unigrams'), \n",
        "                                                      F.col('filtered_ngrams')))"
      ],
      "metadata": {
        "id": "sowTzoKrYeBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_review.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1iumgBm1vHR",
        "outputId": "d8a04870-18af-435e-9adf-c927f9e8ff78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|   finished_unigrams|     finished_ngrams|        finished_pos| finished_pos_ngrams|   filtered_unigrams|     filtered_ngrams|               final|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|procedure total h...|[procedure, total...|[procedure, total...|[NN, JJ, NN, NN, ...|[NN, JJ, NN, NN, ...|[procedure, total...|[procedure_total,...|[procedure, total...|\n",
            "|procedure perform...|[procedure, perfo...|[procedure, perfo...|[NN, NN, NN, NN, ...|[NN, NN, NN, NN, ...|[procedure, perfo...|[procedure_perfor...|[procedure, perfo...|\n",
            "|preop diagnoses 1...|[preop, diagnosis...|[preop, diagnosis...|[NN, NN, NN, NN, ...|[NN, NN, NN, NN, ...|[preop, diagnosis...|[preop_diagnosis,...|[preop, diagnosis...|\n",
            "|preoperative diag...|[preoperative, di...|[preoperative, di...|[JJ, NN, NN, NN, ...|[JJ, NN, NN, NN, ...|[preoperative, di...|[preoperative_dia...|[preoperative, di...|\n",
            "|preoperative diag...|[preoperative, di...|[preoperative, di...|[JJ, NN, JJ, NN, ...|[JJ, NN, JJ, NN, ...|[preoperative, di...|[preoperative_dia...|[preoperative, di...|\n",
            "|the patient was c...|[patient, consent...|[the, patient, be...|[DT, NN, VB, NN, ...|[DT, NN, VB, NN, ...|[consent, skin, b...|[be_consent, skin...|[consent, skin, b...|\n",
            "|preoperative diag...|[preoperative, di...|[preoperative, di...|[JJ, NN, NN, NN, ...|[JJ, NN, NN, NN, ...|[preoperative, di...|[preoperative_dia...|[preoperative, di...|\n",
            "|preoperative diag...|[preoperative, di...|[preoperative, di...|[JJ, NN, NN, NN, ...|[JJ, NN, NN, NN, ...|[preoperative, di...|[preoperative_dia...|[preoperative, di...|\n",
            "|preoperative diag...|[preoperative, di...|[preoperative, di...|[JJ, NN, NN, NN, ...|[JJ, NN, NN, NN, ...|[preoperative, di...|[preoperative_dia...|[preoperative, di...|\n",
            "|admitting diagnos...|[admit, diagnosis...|[admit, diagnosis...|[NN, NN, NN, NN, ...|[NN, NN, NN, NN, ...|[admit, diagnosis...|[admit_diagnosis,...|[admit, diagnosis...|\n",
            "|reason for consul...|[reason, consulta...|[reason, for, con...|[NN, IN, NN, NN, ...|[NN, IN, NN, NN, ...|[reason, mesothel...|[consultation_mes...|[reason, mesothel...|\n",
            "|reason for referr...|[reason, referral...|[reason, for, ref...|[NN, IN, NN, DT, ...|[NN, IN, NN, DT, ...|[reason, patient,...|[hospitalist_serv...|[reason, patient,...|\n",
            "|history of presen...|[history, present...|[history, of, pre...|[NN, IN, JJ, NN, ...|[NN, IN, JJ, NN, ...|[history, illness...|[present_illness,...|[history, illness...|\n",
            "|cc slowing of mot...|[cc, slow, motor,...|[cc, slow, of, mo...|[NN, JJ, IN, NN, ...|[NN, JJ, IN, NN, ...|[cc, slow, skill,...|[cc_slow, motor_s...|[cc, slow, skill,...|\n",
            "|history of presen...|[history, present...|[history, of, pre...|[NN, IN, JJ, NN, ...|[NN, IN, JJ, NN, ...|[history, illness...|[present_illness,...|[history, illness...|\n",
            "|history neurologi...|[history, neurolo...|[history, neurolo...|[NN, JJ, NN, VB, ...|[NN, JJ, NN, VB, ...|[history, neurolo...|[history_neurolog...|[history, neurolo...|\n",
            "|type of consultat...|[type, consultati...|[type, of, consul...|[NN, IN, NN, NN, ...|[NN, IN, NN, NN, ...|[type, wind, care...|[consultation_win...|[type, wind, care...|\n",
            "|the patient is a ...|[patient, yearold...|[the, patient, be...|[DT, NN, VB, DT, ...|[DT, NN, VB, DT, ...|[yearold, female,...|[yearold_female, ...|[yearold, female,...|\n",
            "|chief complaint p...|[chief, complaint...|[chief, complaint...|[JJ, NN, NN, NN, ...|[JJ, NN, NN, NN, ...|[chief, complaint...|[chief_complaint,...|[chief, complaint...|\n",
            "|reason for referr...|[reason, referral...|[reason, for, ref...|[NN, IN, NN, DT, ...|[NN, IN, NN, DT, ...|[reason, patient,...|[yearold_caucasia...|[reason, patient,...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorizer and modeling"
      ],
      "metadata": {
        "id": "ULTWYu08Zfg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import CountVectorizer\n",
        "\n",
        "tfizer = CountVectorizer(inputCol='final', outputCol='tf_features')\n",
        "tf_model = tfizer.fit(processed_review)\n",
        "tf_result = tf_model.transform(processed_review)"
      ],
      "metadata": {
        "id": "SZysVwaKZfmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import IDF\n",
        "\n",
        "idfizer = IDF(inputCol='tf_features', outputCol='tf_idf_features')\n",
        "idf_model = idfizer.fit(tf_result)\n",
        "tfidf_result = idf_model.transform(tf_result)"
      ],
      "metadata": {
        "id": "t-xToiaOZgz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.clustering import LDA\n",
        "\n",
        "num_topics = 25\n",
        "max_iter = 10\n",
        "\n",
        "lda = LDA(k=num_topics, maxIter=max_iter, featuresCol='tf_idf_features')\n",
        "lda_model = lda.fit(tfidf_result)"
      ],
      "metadata": {
        "id": "H-b2oL6NZh-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = tf_model.vocabulary\n",
        "\n",
        "def get_words(token_list):\n",
        "     return [vocab[token_id] for token_id in token_list]\n",
        "       \n",
        "udf_to_words = F.udf(get_words, T.ArrayType(T.StringType()))"
      ],
      "metadata": {
        "id": "aPDO_9nzZjSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_top_words = 10\n",
        "\n",
        "topics = lda_model.describeTopics(num_top_words).withColumn('topicWords', udf_to_words(F.col('termIndices')))\n",
        "topics.select('topic', 'topicWords').show(truncate=90)"
      ],
      "metadata": {
        "id": "avpzxjJAZksa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "defa67ca-ef24-431e-b19e-14d5ea3954dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------------------------------------------------------------------------------------+\n",
            "|topic|                                                                                topicWords|\n",
            "+-----+------------------------------------------------------------------------------------------+\n",
            "|    0|[leave_mandibular, mandibular_dental_abscess, mandibular_dental, extraction, carious_to...|\n",
            "|    1|[preservative, preservative_free, record_complication, epidural, be_inject_neosporin, b...|\n",
            "|    2|[mmddyyyy, renal, renal_cyst, dr_xyz, cell_carcinoma, leave_renal, cyst, carcinoma, che...|\n",
            "|    3|[endoscopy_suite, os, endoscopy, mass_lesion, suite, sims_position, abnormality_friabil...|\n",
            "|    4|[tumor, place, fracture, procedure, right_eye, anesthesia, be_place, incision, remove, ...|\n",
            "|    5|[average_range, premorbid, learn, repetition, high_average_range, task, reportedly, sec...|\n",
            "|    6|[vulgaris_plan_recommend, abnormal_menstrual, good_backflow, discharge_discharge_diagno...|\n",
            "|    7|[disk, artificial_disk, l, great_toe, screw, upper_extremity, low_extremity, fusion, xr...|\n",
            "|    8|[carbohydrate, meal, twohour_postprandial, bedtime_snack, meal_plan, sugar, calory, las...|\n",
            "|    9|[obvious, be_normal, evidence, carotid_artery, normal, palpable, note, carotid, breast,...|\n",
            "|   10|[gastroesophageal, reflux, gastroesophageal_junction, gastroesophageal_reflux, hiatal_h...|\n",
            "|   11|[os, mgdl, temporal, bilateral_babinski, leave_eye, sellar, cn_palsy, sellar_enlargemen...|\n",
            "|   12|[total_knee, knee, knee_replacement, total_knee_replacement, replacement_cataract_enlar...|\n",
            "|   13|              [mg_po, mg, po, daily, po_daily, discharge, history, disorder, insulin, day]|\n",
            "|   14|[fracture, mandible, angle, reduction, internal_fixation, open_reduction, fixation, lea...|\n",
            "|   15|          [os, cn, local_hospital, emergent, od, aneurysm, expressive, brain, mgdl, hr_rr]|\n",
            "|   16|[uterus, uterus_hypermenorrhea, abnormal_uterine_bleed, hypermenorrhea, bleed_enlarge, ...|\n",
            "|   17|[cervical, cervical_epidural, cervical_fusion, steroid_injection, cervical_epidural_ste...|\n",
            "|   18|[mandible, low_lateral_cartilage, fracture, conchal, angle, conchal_cartilage, lateral_...|\n",
            "|   19|[mg_po, insulin_pump, po, insulin_pump_rate, pump_rate, mg, anemia, insulin, central_ca...|\n",
            "+-----+------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_topik = topics.select('topic', 'topicWords').toPandas()"
      ],
      "metadata": {
        "id": "Iu4_Ac05BFBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_topik.to_csv('topic.csv',index=False)"
      ],
      "metadata": {
        "id": "KYeQtAeADayu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('inputdata.csv', index=False)"
      ],
      "metadata": {
        "id": "bFN6Hb6hAzkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as NLP\n",
        "\n",
        "topic = pd.read_csv('topic.csv')\n",
        "inputdata = pd.read_csv('inputdata.csv')\n",
        "\n",
        "def max_distribution(s):\n",
        "    return topic.topicWords.apply(lambda x: x.replace('[', '').replace(']', '').replace(',', '').replace(\"'\", '').split(' ')).apply(lambda x: sum([1 for p in x if p in s]) / len(x)).idxmax()\n",
        "def percentage(s):\n",
        "    return topic.topicWords.apply(lambda x: x.replace('[', '').replace(']', '').replace(',', '').replace(\"'\", '').split(' ')).apply(lambda x: sum([1 for p in x if p in s]) / len(x)).max()\n",
        "\n",
        "inputdata['topic'] = inputdata.text.apply(lambda x: max_distribution(x))\n",
        "inputdata['percentage'] = inputdata.text.apply(lambda x: percentage(x))\n",
        "\n",
        "inputdata[['medical_speciality', 'topic']].groupby('medical_speciality').agg(list)"
      ],
      "metadata": {
        "id": "gQuP6z_0Lz--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X0omKOuNDFJa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RgiqfX5XDqb"
      },
      "source": [
        "## 3. Select the NER model and construct the pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6MDlWmDuaLq"
      },
      "source": [
        "Select the NER model - Lab Results models: **ner_jsl, ner_jsl_enriched**\n",
        "\n",
        "For more details: https://github.com/JohnSnowLabs/spark-nlp-models#pretrained-models---spark-nlp-for-healthcare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "He3s9CAvucfe"
      },
      "outputs": [],
      "source": [
        "# You can change this to the model you want to use and re-run cells below.\n",
        "# Lab models: ner_jsl, ner_jsl_enriched\n",
        "MODEL_NAME = \"ner_clinical_large\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zweiG2ilZqoR"
      },
      "source": [
        "Create the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLuDz_t40be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f52b1752-811b-48b6-f250-4d715db3e341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n",
            "ner_clinical_large download started this may take some time.\n",
            "Approximate size to download 13.9 MB\n",
            "[ | ]\n",
            "An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader.downloadModel.\n",
            ": com.johnsnowlabs.license.exceptions.JslInvalidLicenseException: Cannot check-in the license or license already in use.\n",
            "\tat com.johnsnowlabs.license.FloatingLicense.checkFloatingLicense(Platforms.scala:130)\n",
            "\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment(CheckLicense.scala:37)\n",
            "\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment$(CheckLicense.scala:21)\n",
            "\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader$.checkValidEnvironment(InternalsPythonResourceDownloader.scala:15)\n",
            "\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader$.downloadModel(InternalsPythonResourceDownloader.scala:46)\n",
            "\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader.downloadModel(InternalsPythonResourceDownloader.scala)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
            "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
            "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
            "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
            "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
            "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
            "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
            "[OK!]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-22d519434256>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mword_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordEmbeddingsModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'embeddings_clinical'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clinical/models'\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msetInputCols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msetOutputCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'embeddings'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mclinical_ner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMedicalNerModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clinical/models\"\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0msetInputCols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"document\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"embeddings\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0msetOutputCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ner\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mner_converter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNerConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;34m.\u001b[0m\u001b[0msetInputCols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'token'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ner'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msetOutputCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ner_chunk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sparknlp_jsl/annotator.py\u001b[0m in \u001b[0;36mpretrained\u001b[0;34m(name, lang, remote_loc)\u001b[0m\n\u001b[1;32m   6178\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0msparknlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResourceDownloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6179\u001b[0m         return ResourceDownloader.downloadModel(MedicalNerModel, name, lang, remote_loc,\n\u001b[0;32m-> 6180\u001b[0;31m                                                 j_dwn='InternalsPythonResourceDownloader')\n\u001b[0m\u001b[1;32m   6181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sparknlp/pretrained.py\u001b[0m in \u001b[0;36mdownloadModel\u001b[0;34m(reader, name, language, remote_loc, j_dwn)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mstop_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sparknlp/pretrained.py\u001b[0m in \u001b[0;36mdownloadModel\u001b[0;34m(reader, name, language, remote_loc, j_dwn)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mj_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DownloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremote_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj_dwn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sparknlp/internal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, reader, name, language, remote_loc, validator)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremote_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n\u001b[0;32m--> 214\u001b[0;31m                                              name, language, remote_loc)\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sparknlp/internal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, java_obj, *args)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExtendedJavaWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_java_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sparknlp/internal.py\u001b[0m in \u001b[0;36mnew_java_obj\u001b[0;34m(self, java_class, *args)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_java_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_java_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_java_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpylist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader.downloadModel.\n: com.johnsnowlabs.license.exceptions.JslInvalidLicenseException: Cannot check-in the license or license already in use.\n\tat com.johnsnowlabs.license.FloatingLicense.checkFloatingLicense(Platforms.scala:130)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment(CheckLicense.scala:37)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment$(CheckLicense.scala:21)\n\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader$.checkValidEnvironment(InternalsPythonResourceDownloader.scala:15)\n\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader$.downloadModel(InternalsPythonResourceDownloader.scala:46)\n\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader.downloadModel(InternalsPythonResourceDownloader.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
          ]
        }
      ],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol('text')\\\n",
        "    .setOutputCol('document')\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "    .setInputCols(['sentence']) \\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "word_embeddings = WordEmbeddingsModel.pretrained('embeddings_clinical', 'en', 'clinical/models') \\\n",
        "    .setInputCols(['document', 'token']) \\\n",
        "    .setOutputCol('embeddings')\n",
        "\n",
        "clinical_ner = MedicalNerModel.pretrained(MODEL_NAME, \"en\", \"clinical/models\") \\\n",
        "          .setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
        "          .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = NerConverter()\\\n",
        "    .setInputCols(['sentence', 'token', 'ner']) \\\n",
        "    .setOutputCol('ner_chunk')\n",
        "\n",
        "nlp_pipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    sentence_detector,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    clinical_ner,\n",
        "    ner_converter])\n",
        "\n",
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "pipelineModel = nlpPipeline.fit(empty_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`MedicalNerModel is limited`"
      ],
      "metadata": {
        "id": "qCN_n5gFe1tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# alternative\n",
        "documentAssembler = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "      .setInputCols([\"document\"]) \\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "glove_embeddings = WordEmbeddingsModel.pretrained('glove_100d')\\\n",
        "          .setInputCols([\"document\", \"token\"])\\\n",
        "          .setOutputCol(\"embeddings\")\n",
        "\n",
        "onto_ner = NerDLModel.pretrained(\"onto_100\", 'en') \\\n",
        "          .setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
        "          .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = NerConverter() \\\n",
        "          .setInputCols([\"document\", \"token\", \"ner\"]) \\\n",
        "          .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[\n",
        "          documentAssembler, \n",
        "          tokenizer,\n",
        "          glove_embeddings,\n",
        "          onto_ner,\n",
        "          ner_converter\n",
        "])\n",
        "\n",
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "pipelineModel = nlpPipeline.fit(empty_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_ffWgK1ZQ87",
        "outputId": "2d696900-0bea-4221-f6af-2f3c3d440269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n",
            "onto_100 download started this may take some time.\n",
            "Approximate size to download 13.5 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipelineModel.transform(review_text.limit(10))\n",
        "\n",
        "result.select(F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "        F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsEeNRHCRdNq",
        "outputId": "3a589b5d-3f6b-449a-f5e0-029a17f22817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+---------+\n",
            "|chunk          |ner_label|\n",
            "+---------------+---------+\n",
            "|1              |CARDINAL |\n",
            "|5 ml           |QUANTITY |\n",
            "|2%             |CARDINAL |\n",
            "|12             |CARDINAL |\n",
            "|5700           |CARDINAL |\n",
            "|3              |CARDINAL |\n",
            "|4              |CARDINAL |\n",
            "|second         |ORDINAL  |\n",
            "|10-0           |PRODUCT  |\n",
            "|02 ml          |QUANTITY |\n",
            "|1              |CARDINAL |\n",
            "|2              |CARDINAL |\n",
            "|1              |CARDINAL |\n",
            "|2              |CARDINAL |\n",
            "|1              |CARDINAL |\n",
            "|2              |CARDINAL |\n",
            "|less than 10 ml|QUANTITY |\n",
            "|6/15/2009      |DATE     |\n",
            "|1st            |ORDINAL  |\n",
            "|1              |CARDINAL |\n",
            "+---------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import types as T\n",
        "\n",
        "processed_review = pipelineModel.transform(review_text)\n",
        "\n",
        "processed_review  = processed_review.withColumn('final', F.col('ner_chunk.result'))\n",
        "# processed_review.limit(2).show()"
      ],
      "metadata": {
        "id": "z3UD9agDcPbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "NerVisualizer().display(\n",
        "    result = result.collect()[0],\n",
        "    label_col = 'ner_chunk',\n",
        "    document_col = 'document'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "8AFytnujmGuF",
        "outputId": "7bf05d86-a4ae-49c0-b1c0-b18c050d4165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
              "    \n",
              "    .spark-nlp-display-scroll-entities {\n",
              "        border: 1px solid #E7EDF0;\n",
              "        border-radius: 3px;\n",
              "        text-align: justify;\n",
              "        \n",
              "    }\n",
              "    .spark-nlp-display-scroll-entities span {  \n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #536B76;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-wrapper{\n",
              "    \n",
              "        display: inline-grid;\n",
              "        text-align: center;\n",
              "        border-radius: 4px;\n",
              "        margin: 0 2px 5px 2px;\n",
              "        padding: 1px\n",
              "    }\n",
              "    .spark-nlp-display-entity-name{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        background: #f1f2f3;\n",
              "        border-width: medium;\n",
              "        text-align: center;\n",
              "        \n",
              "        font-weight: 400;\n",
              "        \n",
              "        border-radius: 5px;\n",
              "        padding: 2px 5px;\n",
              "        display: block;\n",
              "        margin: 3px 2px;\n",
              "    \n",
              "    }\n",
              "    .spark-nlp-display-entity-type{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-resolution{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Vistol Regular', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-others{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        font-weight: 400;\n",
              "    }\n",
              "\n",
              "</style>\n",
              " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">procedure total hip replacement  procedure description the patient was bought to the operating room and placed in the supine position after induction of anesthesia the patient was turned on the side and secured in the hip table an incision was made centered over the greater trochanter dissection was sharply carried down through the subcutaneous tissues the gluteus maximus was incised and split proximally the piriformis and external rotators were identified these were removed from their insertions on the greater trochanter as a sleeve with the hip capsule the hip was dislocated a femoral neck cut was made using the guidance of preoperative templating the femoral head was removed extensive degenerative disease was found on the femoral head as well as in the acetabulum  baseline leg-length measurements were taken the femur was retracted anteriorly and a complete labrectomy was performed reaming of the acetabulum was then performed until adequate bleeding subchondral bone was identified in the key areas the trial shell was placed and found to have an excellent fit the real shell was opened and impacted into position in the appropriate amount of anteversion and abduction screws were placed by drilling into the pelvis measuring and placing the appropriate length screw excellent purchase was obtained the trial liner was placed  the femur was then flexed and internally rotated the extra trochanteric bone was removed as was any leftover lateral soft tissue at the piriformis insertion an intramedullary hole was drilled into the femur to define the canal reaming was performed until the appropriate size was reached the broaches were then used to prepare the femur with the appropriate amount of version once the appropriate size broach was reached it was used as a trial with head and neck placement hip range-of-motion was checked in all planes including flexion-internal rotation the position of sleep and extension-external rotation the hip was found to have excellent stability with the final chosen head-neck combination leg length measurements were taken and found to be within acceptable range given the necessity for stability  the real stem was opened and impacted into position the real head was impacted atop the stem if cement was used the canal was thoroughly washed and dried and plugged with a restrictor and then the cement was injected and pressurized and the stem was implanted in the appropriate version excess cement was removed from the edges of the component range of motion and stability were once again checked and found to be excellent adequate hemostasis was obtained vigorous power irrigation was used to remove all debris from the joint prior to final reduction  the arthrotomy and rotators were closed using </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #931EB3\"><span class=\"spark-nlp-display-entity-name\">1 </span><span class=\"spark-nlp-display-entity-type\">CARDINAL</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> ethibond through drill holes in the bone recreating the posterior hip structural anatomy the gluteus maximus was repaired using 0 ethibond and 0 vicryl the subcutaneous tissues were closed after further irrigation with 2-0 vicryl and monocryl sutures the skin was closed with nylon xeroform and a sterile dressing were applied followed by a cold pack and ace wrap the patient was transferred to the recovery room in stable condition having tolerated the procedure well</span></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorizer and modeling"
      ],
      "metadata": {
        "id": "XeIp8xmoIrA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import CountVectorizer\n",
        "\n",
        "tfizer = CountVectorizer(inputCol='final', outputCol='tf_features')\n",
        "tf_model = tfizer.fit(processed_review)\n",
        "tf_result = tf_model.transform(processed_review)"
      ],
      "metadata": {
        "id": "X2ADDuFfIrA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import IDF\n",
        "\n",
        "idfizer = IDF(inputCol='tf_features', outputCol='tf_idf_features')\n",
        "idf_model = idfizer.fit(tf_result)\n",
        "tfidf_result = idf_model.transform(tf_result)"
      ],
      "metadata": {
        "id": "rco-pZSJIrA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.clustering import LDA\n",
        "\n",
        "num_topics = 25\n",
        "max_iter = 10\n",
        "\n",
        "lda = LDA(k=num_topics, maxIter=max_iter, featuresCol='tf_idf_features')\n",
        "lda_model = lda.fit(tfidf_result)"
      ],
      "metadata": {
        "id": "LtmuAXDnIrA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = tf_model.vocabulary\n",
        "\n",
        "def get_words(token_list):\n",
        "     return [vocab[token_id] for token_id in token_list]\n",
        "       \n",
        "udf_to_words = F.udf(get_words, T.ArrayType(T.StringType()))"
      ],
      "metadata": {
        "id": "cE739M3HIrA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_top_words = 10\n",
        "\n",
        "topics = lda_model.describeTopics(num_top_words).withColumn('topicWords', udf_to_words(F.col('termIndices')))\n",
        "topics.select('topic', 'topicWords').show(truncate=90)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d43a5899-0171-41af-bf97-f99bdd0ce1e6",
        "id": "HIOIeJYeIrA4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------------------------------------------------------------------------------------+\n",
            "|topic|                                                                                topicWords|\n",
            "+-----+------------------------------------------------------------------------------------------+\n",
            "|    0|[1992, one month, as long as 25 years, early 12/90, hx 37, the early morning hours, 11/...|\n",
            "|    1|[1 day, 2 hz, 90 seconds, the next day, 15-20 minutes, approximately 1 week, 1 millisec...|\n",
            "|    2|[about 15 cm, 2 to 3, 1 cm, 4-0, 60s, approximately 150 ml, 1936, 3 ounces, 14 minutes,...|\n",
            "|    3|               [5%, 40, approximately 5%, 88, 3  2, 3  3, 01 mg/ml, 98, 40 pounds, winter]|\n",
            "|    4|[six months, the past several months, 1975 and 1985, 11/23/09, 13 months ago, 117/78 rr...|\n",
            "|    5|[2 mm, fifth, 4 mm, one-third, 50-year-old, 97/65 mmhg, 198, 152/92, that evening, appr...|\n",
            "|    6|                                           [one, 1, 5, today, 3, 4, 5 mg, 50, 08/2009, 25]|\n",
            "|    7|       [96 kilogram, all other days, 1 po, 403, 050, 1995, 90 seconds, 7 pound, 208, 2 q6]|\n",
            "|    8|[1 ml, 07/17/2006, every 8 hours, 1333, 50 ml, 1102, 08/16/2006, an ex-32 weeks, 46 d10...|\n",
            "|    9|                [mid night, 3rd, 325 mg, 1994, 60s, 03, 9 mg, 19 blake, 54 mg, about 1 cm]|\n",
            "|   10|[56, 03, 142 per minute, 271 lbs, 3 x 3 cm, 33, every six months, the next several week...|\n",
            "|   11|        [15, second, the next three to five days, 100%, 17, 150 ml, 77-year-old, 2, 22, 6]|\n",
            "|   12|[5 40 one, age 32, age 27, 3 hours, july 25 2006, four weeks, fourth, 7242, age 40, 36-...|\n",
            "|   13|                 [the day, 75, 5-year-old, 150 pm, 112/65, 165 kg, 99%, 91%, 105, 07/2007]|\n",
            "|   14|[sixth, 15 cm, 40 cm, 2000, december 2006, monday wednesday, friday, around mid night, ...|\n",
            "|   15|                                       [two, first, three, 12 mm, 0, four, 1, 2 cm, 28, 2]|\n",
            "|   16|[c6-c7, c5-c6 2, c5-c6, c5-c6 7, c5-c6 5, c5-c6 9, c7, approximately 5 mm, c6-c7 6, 44-mm]|\n",
            "|   17|[3 cm, approximately 2 cm, winters, x48 hours, 1600, one liter, 400, this morning, 14, ...|\n",
            "|   18|[less than 2 ml, 3, 2, 08/17/03, 08/07/2003 secondary, 1, approximately 15 ml, 9/5, 025...|\n",
            "|   19|[164, 18 ml, 75th and 90th, 205, 04 milligrams, 370, 82%, 100 milligrams 100 ml, 98 ml,...|\n",
            "+-----+------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_topik = topics.select('topic', 'topicWords').toPandas()"
      ],
      "metadata": {
        "id": "ItLJdQZQIrA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_topik.to_csv('topic_with_ner.csv',index=False)"
      ],
      "metadata": {
        "id": "DaOUpHmgIrA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('inputdata_with_ner.csv', index=False)"
      ],
      "metadata": {
        "id": "WIU2beRDIrA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as NLP\n",
        "\n",
        "topic = pd.read_csv('topic_with_ner.csv')\n",
        "inputdata = pd.read_csv('inputdata_with_ner.csv')\n",
        "\n",
        "def max_distribution(s):\n",
        "    return topic.topicWords.apply(lambda x: x.replace('[', '').replace(']', '').replace(',', '').replace(\"'\", '').split(' ')).apply(lambda x: sum([1 for p in x if p in s]) / len(x)).idxmax()\n",
        "def percentage(s):\n",
        "    return topic.topicWords.apply(lambda x: x.replace('[', '').replace(']', '').replace(',', '').replace(\"'\", '').split(' ')).apply(lambda x: sum([1 for p in x if p in s]) / len(x)).max()\n",
        "\n",
        "inputdata['topic'] = inputdata.text.apply(lambda x: max_distribution(x))\n",
        "inputdata['percentage'] = inputdata.text.apply(lambda x: percentage(x))\n",
        "\n",
        "inputdata[['medical_speciality', 'topic']].groupby('medical_speciality').agg(list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "f8HM1YGUXutL",
        "outputId": "11795723-c92e-44aa-dfbe-389ad021c56d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                               topic\n",
              "medical_speciality                                                  \n",
              "Cardiovascular / Pulmonary         [6, 6, 15, 3, 15, 6, 15, 6, 4, 6]\n",
              "Consult - History and Phy.          [6, 6, 6, 6, 6, 6, 6, 10, 0, 15]\n",
              "Dentistry                           [6, 6, 2, 6, 15, 15, 6, 6, 6, 6]\n",
              "Dermatology                       [15, 15, 6, 6, 6, 15, 15, 0, 6, 6]\n",
              "Discharge Summary                   [6, 15, 6, 6, 6, 6, 6, 6, 15, 6]\n",
              "ENT - Otolaryngology               [6, 1, 6, 18, 6, 18, 15, 6, 6, 5]\n",
              "Emergency Room Reports             [6, 3, 6, 6, 6, 15, 1, 15, 15, 6]\n",
              "Gastroenterology                  [6, 6, 6, 6, 15, 21, 15, 0, 3, 15]\n",
              "General Medicine                     [6, 6, 6, 6, 6, 6, 6, 6, 0, 15]\n",
              "Hematology - Oncology              [6, 17, 15, 3, 4, 12, 6, 6, 6, 6]\n",
              "Nephrology                         [1, 6, 1, 1, 15, 6, 15, 6, 6, 12]\n",
              "Neurology                         [15, 22, 24, 6, 0, 6, 6, 6, 17, 0]\n",
              "Neurosurgery                       [17, 17, 6, 3, 16, 6, 6, 6, 6, 6]\n",
              "Obstetrics / Gynecology           [17, 6, 2, 6, 6, 17, 6, 15, 15, 6]\n",
              "Office Notes                    [15, 4, 21, 15, 15, 6, 15, 12, 3, 6]\n",
              "Ophthalmology                     [6, 6, 17, 6, 3, 15, 6, 15, 15, 6]\n",
              "Orthopedic                         [1, 15, 6, 16, 3, 6, 6, 15, 6, 6]\n",
              "Pain Management                      [6, 6, 6, 6, 6, 6, 6, 1, 15, 6]\n",
              "Pediatrics - Neonatal               [3, 6, 13, 6, 6, 8, 6, 2, 6, 11]\n",
              "Podiatry                            [1, 6, 12, 6, 21, 6, 6, 3, 6, 6]\n",
              "Psychiatry / Psychology              [6, 6, 15, 6, 5, 6, 3, 6, 6, 6]\n",
              "Radiology                      [15, 23, 15, 6, 6, 15, 15, 19, 15, 3]\n",
              "SOAP / Chart / Progress Notes        [15, 6, 6, 6, 6, 4, 0, 6, 6, 3]\n",
              "Surgery                           [15, 6, 18, 3, 6, 0, 6, 15, 18, 6]\n",
              "Urology                           [6, 15, 3, 17, 15, 6, 6, 17, 6, 2]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34f65d6d-80ab-4157-b366-dfa26c2b5fc5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>medical_speciality</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cardiovascular / Pulmonary</th>\n",
              "      <td>[6, 6, 15, 3, 15, 6, 15, 6, 4, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Consult - History and Phy.</th>\n",
              "      <td>[6, 6, 6, 6, 6, 6, 6, 10, 0, 15]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dentistry</th>\n",
              "      <td>[6, 6, 2, 6, 15, 15, 6, 6, 6, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dermatology</th>\n",
              "      <td>[15, 15, 6, 6, 6, 15, 15, 0, 6, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Discharge Summary</th>\n",
              "      <td>[6, 15, 6, 6, 6, 6, 6, 6, 15, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENT - Otolaryngology</th>\n",
              "      <td>[6, 1, 6, 18, 6, 18, 15, 6, 6, 5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Emergency Room Reports</th>\n",
              "      <td>[6, 3, 6, 6, 6, 15, 1, 15, 15, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gastroenterology</th>\n",
              "      <td>[6, 6, 6, 6, 15, 21, 15, 0, 3, 15]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>General Medicine</th>\n",
              "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 0, 15]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hematology - Oncology</th>\n",
              "      <td>[6, 17, 15, 3, 4, 12, 6, 6, 6, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nephrology</th>\n",
              "      <td>[1, 6, 1, 1, 15, 6, 15, 6, 6, 12]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neurology</th>\n",
              "      <td>[15, 22, 24, 6, 0, 6, 6, 6, 17, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neurosurgery</th>\n",
              "      <td>[17, 17, 6, 3, 16, 6, 6, 6, 6, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Obstetrics / Gynecology</th>\n",
              "      <td>[17, 6, 2, 6, 6, 17, 6, 15, 15, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Office Notes</th>\n",
              "      <td>[15, 4, 21, 15, 15, 6, 15, 12, 3, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ophthalmology</th>\n",
              "      <td>[6, 6, 17, 6, 3, 15, 6, 15, 15, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Orthopedic</th>\n",
              "      <td>[1, 15, 6, 16, 3, 6, 6, 15, 6, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pain Management</th>\n",
              "      <td>[6, 6, 6, 6, 6, 6, 6, 1, 15, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pediatrics - Neonatal</th>\n",
              "      <td>[3, 6, 13, 6, 6, 8, 6, 2, 6, 11]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Podiatry</th>\n",
              "      <td>[1, 6, 12, 6, 21, 6, 6, 3, 6, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Psychiatry / Psychology</th>\n",
              "      <td>[6, 6, 15, 6, 5, 6, 3, 6, 6, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Radiology</th>\n",
              "      <td>[15, 23, 15, 6, 6, 15, 15, 19, 15, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SOAP / Chart / Progress Notes</th>\n",
              "      <td>[15, 6, 6, 6, 6, 4, 0, 6, 6, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Surgery</th>\n",
              "      <td>[15, 6, 18, 3, 6, 0, 6, 15, 18, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Urology</th>\n",
              "      <td>[6, 15, 3, 17, 15, 6, 6, 17, 6, 2]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34f65d6d-80ab-4157-b366-dfa26c2b5fc5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34f65d6d-80ab-4157-b366-dfa26c2b5fc5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34f65d6d-80ab-4157-b366-dfa26c2b5fc5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jqb3uZqPIrA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2GGoEwViluNu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NER_kelompok_2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}